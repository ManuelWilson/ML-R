y = c(20, 21, 23, 22, 20, 23, 24, 25, 20, 21,
5, 3, 6, 4, 7, 5, 2, 4)
e = c('a', 'a', 'a','b','a','b', 'b', 'b', 'b', 'a',
'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b')
dataset = data.frame(x, y , e = e %>% as.factor())
ggplot(data = dataset) +
geom_point(aes(x, y, colour = factor(e)))
h2o.init()
dataset_h2o = dataset %>% as.h2o()
h2o_kmeans <- h2o.kmeans(k = 4,
estimate_k = FALSE,
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
pred <- h2o.predict(h2o_kmeans, newdata = dataset_h2o) %>% as.data.frame()
centroids = h2o_kmeans@model$centers %>% as.data.frame()
ggplot() +
geom_point(aes(dataset$x, dataset$y, colour = dataset$e)) +
geom_point(aes(centroids$x, centroids$y), colour = 'black') +
geom_point(
aes(dataset$x, dataset$y, colour = pred$predict  %>% as.factor(), size = 5), shape=1)
centroids
x = c(5, 6, 5, 3, 4, 2, 3, 5, 3, 7,
20, 18, 19, 21, 17, 18, 19, 22)
y = c(20, 21, 23, 22, 20, 23, 24, 25, 20.5, 21,
5, 3, 6, 4, 7, 5, 2, 4)
e = c('a', 'a', 'a','b','a','b', 'b', 'b', 'b', 'a',
'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b')
dataset = data.frame(x, y , e = e %>% as.factor())
ggplot(data = dataset) +
geom_point(aes(x, y, colour = factor(e)))
h2o.init()
dataset_h2o = dataset %>% as.h2o()
h2o_kmeans <- h2o.kmeans(k = 4,
estimate_k = FALSE,
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
pred <- h2o.predict(h2o_kmeans, newdata = dataset_h2o) %>% as.data.frame()
centroids = h2o_kmeans@model$centers %>% as.data.frame()
ggplot() +
geom_point(aes(dataset$x, dataset$y, colour = dataset$e)) +
geom_point(aes(centroids$x, centroids$y), colour = 'black') +
geom_point(
aes(dataset$x, dataset$y, colour = pred$predict  %>% as.factor(), size = 5), shape=1)
x = c(5, 6, 5, 3, 4, 2, 3, 5, 3, 7,
20, 18, 19, 21, 17, 18, 19, 22)
y = c(20, 21, 23, 22, 20, 23, 24, 25, 20, 21,
5, 3, 6, 4, 7, 5, 2, 4)
e = c('a', 'a', 'a','b','a','b', 'b', 'b', 'b', 'a',
'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b')
dataset = data.frame(x, y , e = e %>% as.factor())
ggplot(data = dataset) +
geom_point(aes(x, y, colour = factor(e)))
h2o.init()
dataset_h2o = dataset %>% as.h2o()
h2o_kmeans <- h2o.kmeans(k = 4,
estimate_k = FALSE,
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
pred <- h2o.predict(h2o_kmeans, newdata = dataset_h2o) %>% as.data.frame()
centroids = h2o_kmeans@model$centers %>% as.data.frame()
ggplot() +
geom_point(aes(dataset$x, dataset$y, colour = dataset$e)) +
geom_point(aes(centroids$x, centroids$y), colour = 'black') +
geom_point(
aes(dataset$x, dataset$y, colour = pred$predict  %>% as.factor(), size = 5), shape=1)
a = c('a', 'a', 'a', 'a', 'b', 'b', 'b')
b = c('c', 'd', 'c', 'd', 'c', 'd', 'd')
c = c('e', 'e', 'f', 'f', 'e', 'e', 'f')
dataset = data.frame(a = a %>% as.factor(), b = b %>% as.factor(), c = c %>% as.factor())
dataset
class(dataset$a)
dataset_h2o = dataset %>% as.h2o()
h2o_kmeans <- h2o.kmeans(k = 10,
estimate_k = TRUE,
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
h2o.init()
dataset_h2o = dataset %>% as.h2o()
h2o_kmeans <- h2o.kmeans(k = 5,
estimate_k = TRUE,
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
h2o_kmeans <- h2o.kmeans(k = 5,
estimate_k = FALSE, # Cannot estimate k if data has no numeric columns
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
h2o_kmeans
h2o_kmeans <- h2o.kmeans(k = 3,
estimate_k = FALSE, # Cannot estimate k if data has no numeric columns
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
h2o_kmeans
h2o_kmeans <- h2o.kmeans(k = 2,
estimate_k = FALSE, # Cannot estimate k if data has no numeric columns
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
h2o_kmeans
pred <- h2o.predict(h2o_kmeans, newdata = dataset_h2o) %>% as.data.frame()
pred
dataset
dataset %>% cbind(pred)
a = c('a', 'a', 'a', 'a', 'b', 'b', 'b', 'x')
b = c('c', 'd', 'c', 'd', 'c', 'd', 'd', 'y')
c = c('e', 'e', 'f', 'f', 'e', 'e', 'f', 'z')
dataset = data.frame(a = a %>% as.factor(), b = b %>% as.factor(), c = c %>% as.factor())
h2o.init()
dataset_h2o = dataset %>% as.h2o()
h2o_kmeans <- h2o.kmeans(k = 2,
estimate_k = FALSE, # Cannot estimate k if data has no numeric columns
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
pred <- h2o.predict(h2o_kmeans, newdata = dataset_h2o) %>% as.data.frame()
dataset %>% cbind(pred)
h2o_kmeans <- h2o.kmeans(k = 3,
estimate_k = FALSE, # Cannot estimate k if data has no numeric columns
standardize = FALSE,
seed = 1234,
x = colnames(dataset),
training_frame = dataset_h2o,
score_each_iteration = TRUE)
pred <- h2o.predict(h2o_kmeans, newdata = dataset_h2o) %>% as.data.frame()
dataset %>% cbind(pred)
clear(list = ls())
rm(list = ls())
?kmeans
data(USArrests)
datos <- scale(USArrests)
# Matriz de distancias euclídeas
mat_dist <- dist(x = datos, method = "euclidean")
# Dendrogramas con linkage complete y average
hc_euclidea_complete <- hclust(d = mat_dist, method = "complete")
hc_euclidea_average  <- hclust(d = mat_dist, method = "average")
cor(x = mat_dist, cophenetic(hc_euclidea_complete))
cor(x = mat_dist, cophenetic(hc_euclidea_average))
library(factoextra)
datos <- USArrests
datos <- scale(datos)
set.seed(101)
hc_euclidea_completo <- hclust(d = dist(x = datos, method = "euclidean"),
method = "complete")
fviz_dend(x = hc_euclidea_completo, k = 2, cex = 0.6) +
geom_hline(yintercept = 5.5, linetype = "dashed") +
labs(title = "Herarchical clustering",
subtitle = "Distancia euclídea, Lincage complete, K=2")
cor(x = mat_dist, cophenetic(hc_euclidea_complete))
cor(x = mat_dist, cophenetic(hc_euclidea_average))
cor(x = mat_dist, cophenetic(hc_euclidea_average))
library(factoextra)
datos <- USArrests
datos <- scale(datos)
set.seed(101)
hc_euclidea_completo <- hclust(d = dist(x = datos, method = "euclidean"),
method = "complete")
fviz_dend(x = hc_euclidea_completo, k = 2, cex = 0.6) +
geom_hline(yintercept = 5.5, linetype = "dashed") +
labs(title = "Herarchical clustering",
subtitle = "Distancia euclídea, Lincage complete, K=2")
cophenetic(hc_euclidea_complete)
library(factoextra)
datos <- USArrests
datos <- scale(datos)
set.seed(101)
hc_euclidea_completo <- hclust(d = dist(x = datos, method = "euclidean"),
method = "complete")
fviz_dend(x = hc_euclidea_completo, k = 2, cex = 0.6) +
geom_hline(yintercept = 5.5, linetype = "dashed") +
labs(title = "Herarchical clustering",
subtitle = "Distancia euclídea, Lincage complete, K=2")
hc_euclidea_completo <- hclust(d = dist(x = datos, method = "euclidean"),
method = "complete")
fviz_dend(x = hc_euclidea_completo, k = 2, cex = 0.6) +
geom_hline(yintercept = 5.5, linetype = "dashed") +
labs(title = "Herarchical clustering",
subtitle = "Distancia euclídea, Lincage complete, K=2")
hc_euclidea_completo <- hclust(d = dist(x = datos, method = "euclidean"),
method = "complete")
fviz_dend(x = hc_euclidea_completo, k = 2, cex = 0.6) +
geom_hline(yintercept = 5.5, linetype = "dashed") +
labs(title = "Herarchical clustering",
subtitle = "Distancia euclídea, Lincage complete, K=2")
clusters <- cutree(tree = hc_euclidea_completo, k = 4)
clusters
clusters <- cutree(tree = hc_euclidea_completo, h = 6) # por altura del dendograma
clusters
clusters
?diana
diana
matriz_distancias <- dist(x = datos[, c("x", "y")], method = "euclidean")
datos
fviz_cluster(object = list(data=datos, cluster=cutree(hc_euclidea_completo, k=4)),
ellipse.type = "convex", repel = TRUE, show.clust.cent = FALSE,
labelsize = 8)  +
labs(title = "Hierarchical clustering + Proyección PCA",
subtitle = "Distancia euclídea, Lincage complete, K=4") +
theme_bw() +
theme(legend.position = "bottom")
datos
fuzzy_cluster <- fanny(x = datos, diss = FALSE, k = 3, metric = "euclidean",
stand = FALSE)
data("USArrests")
datos <- scale(USArrests)
library(cluster)
fuzzy_cluster <- fanny(x = datos, diss = FALSE, k = 3, metric = "euclidean",
stand = FALSE)
head(fuzzy_cluster$membership) #matriz con el grado de pertenencia a cada cluster
fuzzy_cluster$coeff
#plot
library(factoextra)
fviz_cluster(object = fuzzy_cluster, repel = TRUE, ellipse.type = "norm",
pallete = "jco") + theme_bw() + labs(title = "Fuzzy Cluster plot")
library(mclust)
data("diabetes")
head(diabetes)
library(mclust)
install.packages('mclust')
library(mclust)
library(mclust)
data("diabetes")
head(diabetes)
datos <- scale(diabetes[, -1])
# Model-based-clustering
model_clustering <- Mclust(data = datos, G = 1:10)
summary(model_clustering)
library(factoextra)
data("multishapes")
datos <- multishapes[, 1:2]
set.seed(321)
km_clusters <- kmeans(x = datos, centers = 5, nstart = 50)
fviz_cluster(object = km_clusters, data = datos, geom = "point", ellipse = FALSE,
show.clust.cent = FALSE, pallete = "jco") +
theme_bw() +
theme(legend.position = "none")
fviz_cluster(object = dbscan_cluster, data = datos, stand = FALSE,
geom = "point", ellipse = FALSE, show.clust.cent = FALSE,
pallete = "jco") +
theme_bw() +
theme(legend.position = "bottom")
#
set.seed(321)
# DBSCAN con epsilon = 0.15 y minPts = 5
dbscan_cluster <- fpc::dbscan(data = datos, eps = 0.15, MinPts = 5)
# Resultados de la asignación
head(dbscan_cluster$cluster)
fviz_cluster(object = dbscan_cluster, data = datos, stand = FALSE,
geom = "point", ellipse = FALSE, show.clust.cent = FALSE,
pallete = "jco") +
theme_bw() +
theme(legend.position = "bottom")
# DBSCAN con epsilon = 0.15 y minPts = 5
dbscan_cluster <- fpc::dbscan(data = datos, eps = 0.15, MinPts = 5)
library(fpc)
source("~/R/using-ml/clustering.R", encoding = 'UTF-8', echo=TRUE)
# Density-based spatial clustering of applications with noise (DBSCAN) ----
# identificando regiones con alta densidad de observaciones separadas por regiones de baja densidad
install.packages('fpc')
install.packages('dbscan')
library(fpc)
library(dbscan)
library(factoextra)
library(fpc)
library(dbscan)
library(factoextra)
#kmeans
km_clusters <- kmeans(x = datos, centers = 5, nstart = 50)
fviz_cluster(object = km_clusters, data = datos, geom = "point", ellipse = FALSE,
show.clust.cent = FALSE, pallete = "jco") +
theme_bw() +
theme(legend.position = "none")
# DBSCAN con epsilon = 0.15 y minPts = 5
dbscan_cluster <- fpc::dbscan(data = datos, eps = 0.15, MinPts = 5)
# Resultados de la asignación
head(dbscan_cluster$cluster)
fviz_cluster(object = dbscan_cluster, data = datos, stand = FALSE,
geom = "point", ellipse = FALSE, show.clust.cent = FALSE,
pallete = "jco") +
theme_bw() +
theme(legend.position = "bottom")
dbscan_cluster$cluster
# Selección del valor óptimo de epsilon. Como valor de minPts se emplea 5.
dbscan::kNNdistplot(datos, k = 5)
# DBSCAN con epsilon = 0.15 y minPts = 5
dbscan_cluster <- fpc::dbscan(data = datos, eps = 0.15, MinPts = 5)
# Resultados de la asignación
head(dbscan_cluster$cluster)
fviz_cluster(object = dbscan_cluster, data = datos, stand = FALSE,
geom = "point", ellipse = FALSE, show.clust.cent = FALSE,
pallete = "jco") +
theme_bw() +
theme(legend.position = "bottom")
# Visualización de los clusters
fviz_cluster(object = dbscan_cluster, data = datos, stand = FALSE,
geom = "point", ellipse = FALSE, show.clust.cent = FALSE,
pallete = "jco") +
theme_bw() +
theme(legend.position = "bottom")
datos
data("multishapes")
datos <- multishapes[, 1:2]
set.seed(321)
#kmeans
km_clusters <- kmeans(x = datos, centers = 5, nstart = 50)
# Selección del valor óptimo de epsilon. Como valor de minPts se emplea 5.
dbscan::kNNdistplot(datos, k = 5)
# DBSCAN con epsilon = 0.15 y minPts = 5
dbscan_cluster <- fpc::dbscan(data = datos, eps = 0.15, MinPts = 5)
# Resultados de la asignación
head(dbscan_cluster$cluster)
# Visualización de los clusters
fviz_cluster(object = dbscan_cluster, data = datos, stand = FALSE,
geom = "point", ellipse = FALSE, show.clust.cent = FALSE,
pallete = "jco") +
theme_bw() +
theme(legend.position = "bottom")
# Selección del valor óptimo de epsilon. Como valor de minPts se emplea 5.
dbscan::kNNdistplot(datos, k = 5)
# DBSCAN con epsilon = 0.15 y minPts = 5
dbscan_cluster <- fpc::dbscan(data = datos, eps = 0.15, MinPts = 5)
# Resultados de la asignación
head(dbscan_cluster$cluster)
# Visualización de los clusters
fviz_cluster(object = dbscan_cluster, data = datos, stand = FALSE,
geom = "point", ellipse = FALSE, show.clust.cent = FALSE,
pallete = "jco") +
theme_bw() +
theme(legend.position = "bottom")
# Resultados de la asignación
head(dbscan_cluster$cluster)
table(dbscan_cluster$cluster)
# Modelo isolation forest
isoforest <- isolationForest$new(
sample_size = as.integer(nrow(datos)/2),
num_trees   = 500,
replace     = TRUE,
seed        = 123
)
install.packages('solitude')
library(solitude)
library(solitude)
# Modelo isolation forest
isoforest <- isolationForest$new(
sample_size = as.integer(nrow(datos)/2),
num_trees   = 500,
replace     = TRUE,
seed        = 123
)
install.packages('solitude')
install.packages("solitude")
predicciones <- isoforest$predict(
data = datos %>% select(-y)
)
head(predicciones)
# Modelo isolation forest
isoforest <- isolationForest$new(
sample_size = as.integer(nrow(datos)/2),
num_trees   = 500,
replace     = TRUE,
seed        = 123
)
library(solitude)
# Modelo isolation forest
isoforest <- isolationForest$new(
sample_size = as.integer(nrow(datos)/2),
num_trees   = 500,
replace     = TRUE,
seed        = 123
)
isoforest$fit(dataset = datos %>% select(-y))
library(dplyr)
predicciones <- isoforest$predict(
data = datos %>% select(-y)
)
isoforest$fit(dataset = datos %>% select(-y))
predicciones <- isoforest$predict(
data = datos %>% select(-y)
)
head(predicciones)
ggplot(data = predicciones, aes(x = average_depth)) +
geom_histogram(color = "gray40") +
geom_vline(
xintercept = quantile(predicciones$average_depth, seq(0, 1, 0.1)),
color      = "red",
linetype   = "dashed") +
labs(
title = "Distribución de las distancias medias del Isolation Forest",
subtitle = "Cuantiles marcados en rojo"  ) +
theme_bw()
library(ggplot)
library(ggplot2)
ggplot(data = predicciones, aes(x = average_depth)) +
geom_histogram(color = "gray40") +
geom_vline(
xintercept = quantile(predicciones$average_depth, seq(0, 1, 0.1)),
color      = "red",
linetype   = "dashed") +
labs(
title = "Distribución de las distancias medias del Isolation Forest",
subtitle = "Cuantiles marcados en rojo"  ) +
theme_bw()
cuantiles <- quantile(x = predicciones$average_depth, probs = seq(0, 1, 0.05))
cuantiles
datos <- datos %>%
bind_cols(predicciones)
ggplot(data = datos,
aes(x = y, y = average_depth)) +
geom_jitter(aes(color = y), width = 0.03, alpha = 0.3) +
geom_violin(alpha = 0) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +
stat_summary(fun = "mean", colour = "orangered2", size = 3, geom = "point") +
labs(title = "Distancia promedio en el modelo Isolation Forest",
x = "clasificación (0 = normal, 1 = anomalía)",
y = "Distancia promedio") +
theme_bw() +
theme(legend.position = "none")
ggplot(data = datos,
aes(x = y, y = average_depth)) +
geom_jitter(aes(color = y), width = 0.03, alpha = 0.3) +
geom_violin(alpha = 0) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +
stat_summary(fun = "mean", colour = "orangered2", size = 3, geom = "point") +
labs(title = "Distancia promedio en el modelo Isolation Forest",
x = "clasificación (0 = normal, 1 = anomalía)",
y = "Distancia promedio") +
theme_bw() +
theme(legend.position = "none")
datos
cardio_mat  <- readMat("C:\\Users\\mwils\\Documents\\R\\using-ml\\anomalias\\cardio.mat")
df_cardio   <- as.data.frame(cardio_mat$X)
library(R.matlab)   # Lectura de archivos .mat
library(h2o)        # Modelo isolation forest
library(solitude)   # Modelo isolation forest
library(tidyverse)  # Preparación de datos y gráficos
library(MLmetrics)  # Para matriz de confucion
cardio_mat  <- readMat("C:\\Users\\mwils\\Documents\\R\\using-ml\\anomalias\\cardio.mat")
df_cardio   <- as.data.frame(cardio_mat$X)
df_cardio$y <- as.character(cardio_mat$y) # anomalo = 1
datos <- df_cardio
library(solitude)
library(dplyr)
library(ggplot2)
# Modelo isolation forest
isoforest <- isolationForest$new(
sample_size = as.integer(nrow(datos)/2),
num_trees   = 500,
replace     = TRUE,
seed        = 123
)
isoforest$fit(dataset = datos %>% select(-y))
predicciones <- isoforest$predict(
data = datos %>% select(-y)
)
head(predicciones)
ggplot(data = predicciones, aes(x = average_depth)) +
geom_histogram(color = "gray40") +
geom_vline(
xintercept = quantile(predicciones$average_depth, seq(0, 1, 0.1)),
color      = "red",
linetype   = "dashed") +
labs(
title = "Distribución de las distancias medias del Isolation Forest",
subtitle = "Cuantiles marcados en rojo"  ) +
theme_bw()
cuantiles <- quantile(x = predicciones$average_depth, probs = seq(0, 1, 0.05))
cuantiles
datos <- datos %>%
bind_cols(predicciones)
ggplot(data = datos,
aes(x = y, y = average_depth)) +
geom_jitter(aes(color = y), width = 0.03, alpha = 0.3) +
geom_violin(alpha = 0) +
geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +
stat_summary(fun = "mean", colour = "orangered2", size = 3, geom = "point") +
labs(title = "Distancia promedio en el modelo Isolation Forest",
x = "clasificación (0 = normal, 1 = anomalía)",
y = "Distancia promedio") +
theme_bw() +
theme(legend.position = "none")
resultados <- datos %>%
select(y, average_depth) %>%
arrange(average_depth) %>%
mutate(clasificacion = if_else(row_number() <= 176, "1", "0"))
mat_confusion <- MLmetrics::ConfusionMatrix(
y_pred = resultados$clasificacion,
y_true = resultados$y
)
mat_confusion
